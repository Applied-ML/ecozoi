{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import enformer_with_rope2 as enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title `get_targets(organism)`\n",
    "def get_targets(organism):\n",
    "  targets_txt = f'data/{organism}/targets.txt'\n",
    "  return pd.read_csv(targets_txt, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title `get_dataset(organism, subset, num_threads=8)`\n",
    "import glob\n",
    "import json\n",
    "import functools\n",
    "\n",
    "\n",
    "def organism_path(organism):\n",
    "  return os.path.join('data', organism)\n",
    "\n",
    "\n",
    "def get_dataset(organism, subset, num_threads=8):\n",
    "  metadata = get_metadata(organism)\n",
    "  dataset = tf.data.TFRecordDataset(tfrecord_files(organism, subset),\n",
    "                                    compression_type='ZLIB',\n",
    "                                    num_parallel_reads=num_threads)\n",
    "  dataset = dataset.map(functools.partial(deserialize, metadata=metadata),\n",
    "                        num_parallel_calls=num_threads)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def get_metadata(organism):\n",
    "  # Keys:\n",
    "  # num_targets, train_seqs, valid_seqs, test_seqs, seq_length,\n",
    "  # pool_width, crop_bp, target_length\n",
    "  path = os.path.join(organism_path(organism), 'statistics.json')\n",
    "  with tf.io.gfile.GFile(path, 'r') as f:\n",
    "    return json.load(f)\n",
    "\n",
    "\n",
    "def tfrecord_files(organism, subset):\n",
    "  # Sort the values by int(*).\n",
    "  return sorted(tf.io.gfile.glob(os.path.join(\n",
    "      organism_path(organism), 'tfrecords', f'{subset}-*.tfr'\n",
    "  )), key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "def deserialize(serialized_example, metadata):\n",
    "  \"\"\"Deserialize bytes stored in TFRecordFile.\"\"\"\n",
    "  feature_map = {\n",
    "      'sequence': tf.io.FixedLenFeature([], tf.string),\n",
    "      'target': tf.io.FixedLenFeature([], tf.string),\n",
    "  }\n",
    "  example = tf.io.parse_example(serialized_example, feature_map)\n",
    "  sequence = tf.io.decode_raw(example['sequence'], tf.bool)\n",
    "  sequence = tf.reshape(sequence, (metadata['seq_length'], 4))\n",
    "  sequence = tf.cast(sequence, tf.float32)\n",
    "\n",
    "  target = tf.io.decode_raw(example['target'], tf.float16)\n",
    "  target = tf.reshape(target,\n",
    "                      (metadata['target_length'], metadata['num_targets']))\n",
    "  target = tf.cast(target, tf.float32)\n",
    "\n",
    "  return {'sequence': sequence,\n",
    "          'target': target}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_human = get_targets('human')\n",
    "# df_targets_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dnase = df_targets_human.index[df_targets_human['description'].str[:4] == 'DNAS'].tolist()\n",
    "indices_cage = df_targets_human.index[df_targets_human['description'].str[:4] == 'CAGE'].tolist()\n",
    "indices_chip = df_targets_human.index[df_targets_human['description'].str[:4] == 'CHIP'].tolist()\n",
    "indices_atac = df_targets_human.index[df_targets_human['description'].str[:4] == 'ATAC'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_dataset = get_dataset('human', 'train').batch(1)\n",
    "mouse_dataset = get_dataset('mouse', 'train').batch(1).repeat()\n",
    "human_mouse_dataset = tf.data.Dataset.zip((human_dataset, mouse_dataset)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def komlos_encode(sequence):\n",
    "    \"\"\"Convert one-hot encoded sequence to custom encoding:\n",
    "    A → (+1, +1, −1)\n",
    "    C → (−1, +1, +1)\n",
    "    T → (+1, −1, +1)\n",
    "    G → (−1, −1, −1)\n",
    "    \"\"\"\n",
    "    \n",
    "    a_pos = sequence[:, :, 0]  # A positions\n",
    "    c_pos = sequence[:, :, 1]  # C positions\n",
    "    t_pos = sequence[:, :, 2]  # T positions\n",
    "    g_pos = sequence[:, :, 3]  # G positions\n",
    "    \n",
    "    \n",
    "    dim1 = (a_pos + t_pos) * 1.0 + (c_pos + g_pos) * -1.0  # +1 for A/T, -1 for C/G\n",
    "    dim2 = (a_pos + c_pos) * 1.0 + (t_pos + g_pos) * -1.0  # +1 for A/C, -1 for T/G\n",
    "    dim3 = (a_pos + g_pos) * -1.0 + (t_pos + c_pos) * 1.0  # -1 for A/G, +1 for T/C\n",
    "    \n",
    "    \n",
    "    encoded = tf.stack([dim1, dim2, dim3], axis=-1)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_to_komlos(batch):\n",
    "    batch['sequence'] = komlos_encode(batch['sequence'])\n",
    "    return batch\n",
    "\n",
    "\n",
    "human_dataset = get_dataset('human', 'train').batch(1).map(map_to_komlos)\n",
    "mouse_dataset = get_dataset('mouse', 'train').batch(1).map(map_to_komlos)\n",
    "human_mouse_dataset = tf.data.Dataset.zip((human_dataset, mouse_dataset)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(human_mouse_dataset)\n",
    "# example = next(it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it = iter(human_mouse_dataset)\n",
    "# example = next(it)\n",
    "# for i in range(len(example)):\n",
    "#   print(['human', 'mouse'][i])\n",
    "#   print({k: (v.shape, v.dtype) for k,v in example[i].items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_step_function(model, optimizer):\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(batch, head, optimizer_clip_norm_global=0.2):\n",
    "    with tf.GradientTape() as tape:\n",
    "      outputs = model(batch['sequence'], is_training=True)[head]\n",
    "      loss = tf.reduce_mean(\n",
    "          tf.keras.losses.poisson(batch['target'], outputs))\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "\n",
    "    return loss\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_step_function(model, optimizer):\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(batch, head, optimizer_clip_norm_global=0.2):\n",
    "    with tf.GradientTape() as tape:\n",
    "      outputs = model(batch['sequence'], is_training=True)[head]\n",
    "      loss = tf.reduce_mean(\n",
    "          tf.keras.losses.poisson(batch['target'], outputs))\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply(gradients, model.trainable_variables)\n",
    "\n",
    "    return loss\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = tf.Variable(0., trainable=False, name='learning_rate')\n",
    "optimizer = snt.optimizers.Adam(learning_rate=learning_rate)\n",
    "num_warmup_steps = 5\n",
    "target_learning_rate = 0.0005\n",
    "\n",
    "model = enformer.Enformer(channels=1536//4 ,  # Use 4x fewer channels to train faster.\n",
    "                          num_heads=2,\n",
    "                          num_transformer_layers=11,\n",
    "                          pooling_type='max')\n",
    "\n",
    "train_step = create_step_function(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:06<00:00, 66.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss_human 1.0724628 loss_mouse 1.1818571 learning_rate 0.0\n",
      "CPU times: total: 3min 28s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "steps_per_epoch = 1\n",
    "num_epochs = 1\n",
    "\n",
    "data_it = iter(human_mouse_dataset)\n",
    "global_step = 0\n",
    "for epoch_i in range(num_epochs):\n",
    "  for i in tqdm(range(steps_per_epoch)):\n",
    "    global_step += 1\n",
    "\n",
    "    if global_step > 1:\n",
    "      learning_rate_frac = tf.math.minimum(\n",
    "          1.0, global_step / tf.math.maximum(1.0, num_warmup_steps))      \n",
    "      learning_rate.assign(target_learning_rate * learning_rate_frac)\n",
    "\n",
    "    batch_human, batch_mouse = next(data_it)\n",
    "\n",
    "    loss_human = train_step(batch=batch_human, head='human')\n",
    "    loss_mouse = train_step(batch=batch_mouse, head='mouse')\n",
    "\n",
    "  # End of epoch.\n",
    "  print('')\n",
    "  print('loss_human', loss_human.numpy(),\n",
    "        'loss_mouse', loss_mouse.numpy(),\n",
    "        'learning_rate', optimizer.learning_rate.numpy()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title `PearsonR` and `R2` metrics\n",
    "\n",
    "def _reduced_shape(shape, axis):\n",
    "  if axis is None:\n",
    "    return tf.TensorShape([])\n",
    "  return tf.TensorShape([d for i, d in enumerate(shape) if i not in axis])\n",
    "\n",
    "\n",
    "class CorrelationStats(tf.keras.metrics.Metric):\n",
    "  \"\"\"Contains shared code for PearsonR and R2.\"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=None, name='pearsonr'):\n",
    "    \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation (say\n",
    "        (0, 1). If not specified, it will compute the correlation across the\n",
    "        whole tensor.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(CorrelationStats, self).__init__(name=name)\n",
    "    self._reduce_axis = reduce_axis\n",
    "    self._shape = None  # Specified in _initialize.\n",
    "\n",
    "  def _initialize(self, input_shape):\n",
    "    # Remaining dimensions after reducing over self._reduce_axis.\n",
    "    self._shape = _reduced_shape(input_shape, self._reduce_axis)\n",
    "\n",
    "    weight_kwargs = dict(shape=self._shape, initializer='zeros')\n",
    "    self._count = self.add_weight(name='count', **weight_kwargs)\n",
    "    self._product_sum = self.add_weight(name='product_sum', **weight_kwargs)\n",
    "    self._true_sum = self.add_weight(name='true_sum', **weight_kwargs)\n",
    "    self._true_squared_sum = self.add_weight(name='true_squared_sum',\n",
    "                                             **weight_kwargs)\n",
    "    self._pred_sum = self.add_weight(name='pred_sum', **weight_kwargs)\n",
    "    self._pred_squared_sum = self.add_weight(name='pred_squared_sum',\n",
    "                                             **weight_kwargs)\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    \"\"\"Update the metric state.\n",
    "\n",
    "    Args:\n",
    "      y_true: Multi-dimensional float tensor [batch, ...] containing the ground\n",
    "        truth values.\n",
    "      y_pred: float tensor with the same shape as y_true containing predicted\n",
    "        values.\n",
    "      sample_weight: 1D tensor aligned with y_true batch dimension specifying\n",
    "        the weight of individual observations.\n",
    "    \"\"\"\n",
    "    if self._shape is None:\n",
    "      # Explicit initialization check.\n",
    "      self._initialize(y_true.shape)\n",
    "    y_true.shape.assert_is_compatible_with(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, 'float32')\n",
    "    y_pred = tf.cast(y_pred, 'float32')\n",
    "\n",
    "    self._product_sum.assign_add(\n",
    "        tf.reduce_sum(y_true * y_pred, axis=self._reduce_axis))\n",
    "\n",
    "    self._true_sum.assign_add(\n",
    "        tf.reduce_sum(y_true, axis=self._reduce_axis))\n",
    "\n",
    "    self._true_squared_sum.assign_add(\n",
    "        tf.reduce_sum(tf.math.square(y_true), axis=self._reduce_axis))\n",
    "\n",
    "    self._pred_sum.assign_add(\n",
    "        tf.reduce_sum(y_pred, axis=self._reduce_axis))\n",
    "\n",
    "    self._pred_squared_sum.assign_add(\n",
    "        tf.reduce_sum(tf.math.square(y_pred), axis=self._reduce_axis))\n",
    "\n",
    "    self._count.assign_add(\n",
    "        tf.reduce_sum(tf.ones_like(y_true), axis=self._reduce_axis))\n",
    "\n",
    "  def result(self):\n",
    "    raise NotImplementedError('Must be implemented in subclasses.')\n",
    "\n",
    "  def reset_states(self):\n",
    "    if self._shape is not None:\n",
    "      tf.keras.backend.batch_set_value([(v, np.zeros(self._shape))\n",
    "                                        for v in self.variables])\n",
    "\n",
    "\n",
    "class PearsonR(CorrelationStats):\n",
    "  \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "  Computed as:\n",
    "  ((x - x_avg) * (y - y_avg) / sqrt(Var[x] * Var[y])\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=(0,), name='pearsonr'):\n",
    "    \"\"\"Pearson correlation coefficient.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(PearsonR, self).__init__(reduce_axis=reduce_axis,\n",
    "                                   name=name)\n",
    "\n",
    "  def result(self):\n",
    "    true_mean = self._true_sum / self._count\n",
    "    pred_mean = self._pred_sum / self._count\n",
    "\n",
    "    covariance = (self._product_sum\n",
    "                  - true_mean * self._pred_sum\n",
    "                  - pred_mean * self._true_sum\n",
    "                  + self._count * true_mean * pred_mean)\n",
    "\n",
    "    true_var = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "    pred_var = self._pred_squared_sum - self._count * tf.math.square(pred_mean)\n",
    "    tp_var = tf.math.sqrt(true_var) * tf.math.sqrt(pred_var)\n",
    "    correlation = covariance / tp_var\n",
    "\n",
    "    return correlation\n",
    "\n",
    "\n",
    "class R2(CorrelationStats):\n",
    "  \"\"\"R-squared  (fraction of explained variance).\"\"\"\n",
    "\n",
    "  def __init__(self, reduce_axis=None, name='R2'):\n",
    "    \"\"\"R-squared metric.\n",
    "\n",
    "    Args:\n",
    "      reduce_axis: Specifies over which axis to compute the correlation.\n",
    "      name: Metric name.\n",
    "    \"\"\"\n",
    "    super(R2, self).__init__(reduce_axis=reduce_axis,\n",
    "                             name=name)\n",
    "\n",
    "  def result(self):\n",
    "    true_mean = self._true_sum / self._count\n",
    "    total = self._true_squared_sum - self._count * tf.math.square(true_mean)\n",
    "    residuals = (self._pred_squared_sum - 2 * self._product_sum\n",
    "                 + self._true_squared_sum)\n",
    "\n",
    "    return tf.ones_like(residuals) - residuals / total\n",
    "\n",
    "\n",
    "class MetricDict:\n",
    "  def __init__(self, metrics):\n",
    "    self._metrics = metrics\n",
    "\n",
    "  def update_state(self, y_true, y_pred):\n",
    "    for k, metric in self._metrics.items():\n",
    "      metric.update_state(y_true, y_pred)\n",
    "\n",
    "  def result(self):\n",
    "    return {k: metric.result() for k, metric in self._metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, head, max_steps=None):\n",
    "  metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "  @tf.function\n",
    "  def predict(x):\n",
    "    return model(x, is_training=False)[head]\n",
    "\n",
    "  for i, batch in tqdm(enumerate(dataset)):\n",
    "    if max_steps is not None and i > max_steps:\n",
    "      break\n",
    "    metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "\n",
    "  return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, head, max_steps=None):\n",
    "  metric = MetricDict({'PearsonR': PearsonR(reduce_axis=(0,1))})\n",
    "  @tf.function\n",
    "  def predict(x):\n",
    "    return model(x, is_training=False)[head]\n",
    "\n",
    "  for i, batch in tqdm(enumerate(dataset)):\n",
    "    if max_steps is not None and i > max_steps:\n",
    "      break\n",
    "    metric.update_state(batch['target'], predict(batch['sequence']))\n",
    "\n",
    "  return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 375 ms\n",
      "Wall time: 476 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "human_validation_dataset = get_dataset('human', 'valid').batch(1).prefetch(2).map(map_to_komlos)\n",
    "mouse_validation_dataset = get_dataset('mouse', 'valid').batch(1).prefetch(2).map(map_to_komlos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'PearsonR': 0.00012833522}\n",
      "CPU times: total: 1min 8s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_human = evaluate_model(model,\n",
    "                               dataset=human_validation_dataset,\n",
    "                               head='human',\n",
    "                               max_steps=2)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_human.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to metrics_human.npy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "metrics_human_numpy = {k: v.numpy() for k, v in metrics_human.items()}\n",
    "np.save('metrics_human.npy', metrics_human_numpy)\n",
    "print(\"Metrics saved to metrics_human.npy\")\n",
    "\n",
    "\n",
    "#loaded_metrics = np.load('metrics_human.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dnase = df_targets_human.index[df_targets_human['description'].str[:4] == 'DNAS'].tolist()\n",
    "indices_cage = df_targets_human.index[df_targets_human['description'].str[:4] == 'CAGE'].tolist()\n",
    "indices_chip = df_targets_human.index[df_targets_human['description'].str[:4] == 'CHIP'].tolist()\n",
    "indices_atac = df_targets_human.index[df_targets_human['description'].str[:4] == 'ATAC'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dnase = metrics_human['PearsonR'][indices_dnase[0]:indices_dnase[-1]]\n",
    "results_cage = metrics_human['PearsonR'][indices_cage[0]:indices_cage[-1]]\n",
    "results_chip = metrics_human['PearsonR'][indices_chip[0]:indices_chip[-1]]\n",
    "results_atac = metrics_human['PearsonR'][indices_atac[0]:indices_atac[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNASE Average : -1.202147268486442e-05\n",
      "CAGE Average :0.0010011494159698486\n",
      "CHIP Average : -4.107126187591348e-06\n",
      "ATAC Average :0.004198337439447641\n"
     ]
    }
   ],
   "source": [
    "#Pearson correlation averages across all positions per track (figure 1.C)\n",
    "print(f\"DNASE Average : {np.mean(results_dnase)}\")\n",
    "print(f\"CAGE Average :{np.mean(results_cage)}\")\n",
    "print(f\"CHIP Average : {np.mean(results_chip)}\")\n",
    "print(f\"ATAC Average :{np.mean(results_atac)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:08,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'PearsonR': 0.0008534363}\n",
      "CPU times: total: 1min 2s\n",
      "Wall time: 8.99 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics_mouse = evaluate_model(model,\n",
    "                               dataset=mouse_validation_dataset,\n",
    "                               head='mouse',\n",
    "                               max_steps=2)\n",
    "print('')\n",
    "print({k: v.numpy().mean() for k, v in metrics_mouse.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
